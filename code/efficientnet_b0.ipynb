{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Module importing\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import glob # glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환\n",
    "import cv2 # 이미지 관리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Setting\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 5,\n",
    "    'LEARNING_RATE': 3e-4,\n",
    "    'BATCH_SIZE': 32,\n",
    "    'SEED': 41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed RandomSeed\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed) # random으로 생성한 seed를 고정\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed) # 해시 함수의 랜덤성 제어\n",
    "    np.random.seed(seed) # numpy 랜덤 숫자 고정\n",
    "    torch.manual_seed(seed) # torch 라이브러리에서 cpu 텐서 생성 랜덤 시드 고정\n",
    "    torch.cuda.manual_seed(seed) # cuda의 gpu 텐서에 대한 시드 고정\n",
    "    torch.backends.cudnn.deterministic = True # 백엔드가 결정적 알고리즘만 사용하도록 고정\n",
    "    torch.backends.cudnn.benchmark = True # CuDNN이 여러 내부 휴리스택을 사용하여 가장 빠른 알고리즘을 동적으로 찾도록 설정\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\Project\\Bird_images\n"
     ]
    }
   ],
   "source": [
    "basedir = os.getcwd()\n",
    "print(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Validation Split\n",
    "data_dir = basedir + '/Bird_image_data'\n",
    "df = pd.read_csv(data_dir + '/train.csv')\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>upscale_img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./train/TRAIN_00000.jpg</td>\n",
       "      <td>./upscale_train/TRAIN_00000.png</td>\n",
       "      <td>Ruddy Shelduck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./train/TRAIN_00001.jpg</td>\n",
       "      <td>./upscale_train/TRAIN_00001.png</td>\n",
       "      <td>Gray Wagtail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./train/TRAIN_00002.jpg</td>\n",
       "      <td>./upscale_train/TRAIN_00002.png</td>\n",
       "      <td>Indian Peacock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./train/TRAIN_00003.jpg</td>\n",
       "      <td>./upscale_train/TRAIN_00003.png</td>\n",
       "      <td>Common Kingfisher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./train/TRAIN_00004.jpg</td>\n",
       "      <td>./upscale_train/TRAIN_00004.png</td>\n",
       "      <td>Common Kingfisher</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  img_path                 upscale_img_path              label\n",
       "0  ./train/TRAIN_00000.jpg  ./upscale_train/TRAIN_00000.png     Ruddy Shelduck\n",
       "1  ./train/TRAIN_00001.jpg  ./upscale_train/TRAIN_00001.png       Gray Wagtail\n",
       "2  ./train/TRAIN_00002.jpg  ./upscale_train/TRAIN_00002.png     Indian Peacock\n",
       "3  ./train/TRAIN_00003.jpg  ./upscale_train/TRAIN_00003.png  Common Kingfisher\n",
       "4  ./train/TRAIN_00004.jpg  ./upscale_train/TRAIN_00004.png  Common Kingfisher"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label-Encoding\n",
    "le = preprocessing.LabelEncoder() # 라벨 인코딩을 통해 해당 변수를 정수로 변경\n",
    "# train, label의 라벨 인코딩\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "val['label'] = le.transform(val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./train/TRAIN_02019.jpg' './train/TRAIN_01264.jpg'\n",
      " './train/TRAIN_06609.jpg' ... './train/TRAIN_07446.jpg'\n",
      " './train/TRAIN_09221.jpg' './train/TRAIN_03133.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(train['img_path'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Programming\\Project\\Bird_images/Bird_image_data/train/TRAIN_02019.jpg\n"
     ]
    }
   ],
   "source": [
    "print(data_dir + train['img_path'].values[0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomDataset : 파일 경로와 라벨을 받아, 데이터를 로드하고 전처리하는 데이터셋 생성\n",
    "from PIL import Image\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = data_dir + self.img_path_list[index][1:]\n",
    "        image = cv2.imread(img_path) # 이미지 경로 리스트에서 각 파일 경로 로드\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "\n",
    "        if self.label_list is not None: # 해당 이미지에 라벨이 있을 경우\n",
    "            label = self.label_list[index] # 이미지에 대한 라벨도 함께 반환\n",
    "            return image, label\n",
    "        else: # 라벨이 없을 경우\n",
    "            return image # 이미지만 반환\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "\n",
    "# Compose는 여러 변환을 연속적으로적용할 수 있게 해주는 함수.\n",
    "# (img 사이즈 224로 설정되어 있음)\n",
    "# 이미지 크기조정, 정규화, 텐서로 변환 포함.\n",
    "'''\n",
    "Normalize(mean=0.485, 0.456, 0.406값은 각 채널별 평균)\n",
    "std=(0.229, 0.224, 0.225 값은 각 채널별 표준편차)\n",
    "max_pixel_value: 이미지의 최대 픽셀 값 (8비트의 경우 255가 최대값)\n",
    "always_apply= Ture: 변환이 데이터셋의 모든 이미지에 대해 항상 적용.\n",
    "p: 변환이 적용될 확률: (0~1 사이)\n",
    "대부분의 경우 always_apply=True로 하고 p를 조절해서 사용\n",
    "'''\n",
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "# train dataset 설정 및 로드\n",
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "# val dataset 설정 및 로드\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Define\n",
    "class BaseModel(nn.Module):\n",
    "    #le.classes는 LabelEncoder가 학습한 후에 갖게되는 속성 (고유한 클래스 라벨들의 배열)\n",
    "    def __init__(self, num_classes=len(le.classes_)):\n",
    "        super(BaseModel, self).__init__()\n",
    "        # EfficientNet B0 아키텍처를 사용하여 사전 훈련된 백본 설정. 특성 추출기 역함\n",
    "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "        # 백본 모델의 출력을 받아 최종적으로 클래스 수에 맞는 출력을 생성하는 선형 분류기\n",
    "        self.classifier = nn.Linear(1000, num_classes) #기본 출력크기 1,000으로 정의\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x) #backbone을 거쳐 특성이 추출\n",
    "        x = self.classifier(x) # 분류기에 전달되어 최종 출력 생성\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device) # 모델을 해당 디바이스로 옮김(cpu, gpu)\n",
    "    criterion = nn.CrossEntropyLoss().to(device) # 손실함수 정의하고 해당 device로 옮김\n",
    "\n",
    "    # 성능 기록 초기화\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "\n",
    "    # 설정한 하이퍼파라미터의 epochs만큼 반복\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train() #모델을 훈련모드로 설정\n",
    "        train_loss = []\n",
    "\n",
    "        # 반복을 통해서 배치 단위로 이미지와 라벨을 가져옴\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device) # 이미지를 실수형으로 변경한 후 device로 올림\n",
    "            labels = labels.long().to(device)  # 데이터 타입 long으로 변경한 후 device로 올림 (int로 변경하였을 때, error 발생했음)\n",
    "\n",
    "            optimizer.zero_grad() # 이전 그레디언트가 누적될 가능성이 있으니 초기화\n",
    "\n",
    "            output = model(imgs) # 모델의 이미지를 입력하여 출력을 얻음\n",
    "            loss = criterion(output, labels) # 손실 함수를 통해 손실 값을 계산함.\n",
    "\n",
    "            loss.backward() # 손실에 대한 그레디언트 계산\n",
    "            optimizer.step() # 옵티마이저를 통해 모델의 가중치 업데이트\n",
    "\n",
    "            train_loss.append(loss.item()) # loss.item()은 현재 배치에 대한 손실 값을 파이썬의 floate 타입으로 변환.\n",
    "            # 훈련 과정에서 각 배치를 처리할 때마다 이 줄이 실행되어, 각 배치의 손실 값을 train_loss 리스트에 순차적으로 추가\n",
    "\n",
    "        # 각 에포크마다 validation함수를 호출하여서 검증 세트에서 모델의 성능을 평가\n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss) # 각 배치에서 계산된 모든 손실 값의 평균을 구함\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 Score : [{_val_score:.5f}]')\n",
    "\n",
    "        # scheduler이 설정되어 있다면 검증 성능에 따라 학습률을 조정\n",
    "        if scheduler is not None:\n",
    "            scheduler.step(_val_score)\n",
    "\n",
    "        # 가장 좋은 성능을 보인 모델을 반환\n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval() # 평가모드\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    # 평가모드의 경우에는 gradient를 초기화하는 부분이 없음 (backward 필요없음. 오직 평가만!)\n",
    "    with torch.no_grad(): # 이 블록 내에서 그레디언트 계산을 중단하여, 필요하지 않은 메모리 사용을 줄이고 계산 속도 향상.\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.long().to(device)  # 데이터 타입 long으로 변경한 후 device로 올림 (int로 변경하였을 때, error 발생했음)\n",
    "\n",
    "            pred = model(imgs)\n",
    "\n",
    "            loss = criterion(pred, labels)\n",
    "\n",
    "            # pred는 모델이 반환한 예측값. 각 클래스에 대한 확률 또는 점수를 포함하는 텐서. argmax(1)은 각 샘플에 대해 가장 높은 점수를 가진 클래스의 인덱스를 찾아줌.\n",
    "            # detach()는 현재 계산 그래프로부터 이 텐서를 분리하여, 이후 연산이 그래프에 기록되지 않도록함. 메모리 사용량 줄임\n",
    "            # cpu()는 cpu로 옮김 (GPU에 있었다면)\n",
    "            # numpy()는 텐서를 numpy 배열로 변환\n",
    "            # tolist()는 numpy 배열을 파이썬 리스트로 변환\n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "\n",
    "            # 실제 라벨도 위와 동일한 과정 진행\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "        _val_loss = np.mean(val_loss)\n",
    "        # average = 'macro'는 F1점수를 계산할 때, 각 클래스에 대한 F1점수를 동일한 가중치로 평균내어 전체 클래스에 대한 평균 F1점수를 계산.\n",
    "        # 각 클래스의 샘플 크기와 관계없이 모든 클래스를 동등하게 취급. 이는 클래스 불균형이 있을 때 유용하며, 모든 클래스를 공평하게 평가하고자 할 때 사용.\n",
    "        _val_score = f1_score(true_labels, preds, average='macro')\n",
    "\n",
    "    return _val_loss, _val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\dhsmf/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:14<00:00, 1.47MB/s]\n",
      "100%|██████████| 347/347 [1:33:18<00:00, 16.13s/it]\n",
      "100%|██████████| 149/149 [12:45<00:00,  5.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [1.04251] Val Loss : [0.51467] Val F1 Score : [0.85018]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347 [18:27:20<00:00, 191.47s/it]      \n",
      "100%|██████████| 149/149 [08:27<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.29871] Val Loss : [0.48676] Val F1 Score : [0.86832]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347 [59:53<00:00, 10.35s/it] \n",
      "100%|██████████| 149/149 [06:09<00:00,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.13251] Val Loss : [0.61651] Val F1 Score : [0.85917]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347 [57:43<00:00,  9.98s/it]\n",
      "100%|██████████| 149/149 [06:02<00:00,  2.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.11791] Val Loss : [0.63090] Val F1 Score : [0.84673]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347 [55:50<00:00,  9.65s/it]\n",
      "100%|██████████| 149/149 [05:48<00:00,  2.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.12823] Val Loss : [0.62681] Val F1 Score : [0.85758]\n"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "model = BaseModel() # 모델은 basemodel 가져옴\n",
    "model.eval() #평가모드로 전환 (훈련모드가 아닌 평가모드를 불러온 이유가 뭐지?..)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"]) # optimizer 'adam'으로 설정 / 학습률 위의 하이퍼파라미터\n",
    "\n",
    "#학습률을 동적으로 조정하는 스케줄러 설정. 검증 성능이 개선되지 않으면 학습률 감소.\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(infer_model.state_dict(), 'model_state_dict.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [10:19<00:00,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "test = pd.read_csv(data_dir + '/test.csv')\n",
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "\n",
    "            pred = model(imgs)\n",
    "\n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "\n",
    "    preds = le.inverse_transform(preds)\n",
    "    return preds\n",
    "\n",
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submission\n",
    "submit = pd.read_csv(data_dir + '/sample_submission.csv')\n",
    "submit['label'] = preds\n",
    "submit.to_csv(data_dir + '/baseline_submit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
