{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3_envs\\py310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Module import\n",
    "import os\n",
    "import re\n",
    "# import gc # garbage collection module\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import pytorch_lightning as L\n",
    "from transformers import Swinv2Config, Swinv2Model, AutoImageProcessor, AutoModelForImageClassification\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Setting\n",
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 5,\n",
    "    'LEARNING_RATE': 3e-4,\n",
    "    'BATCH_SIZE': 32,\n",
    "    'SEED': 41\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 41\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd() + '\\..'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = basedir + '/Bird_image_data'\n",
    "df = pd.read_csv(data_dir + '/train.csv')\n",
    "df.head()\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CustomDataset : Dataframe에서 받은 이미지 경로 리스트와 라벨 리스트\n",
    "class CustomDataset(Dataset):\n",
    "    # Dataframe에서 받은 이미지 경로 리스트와 라벨 리스트를 로드\n",
    "    def __init__(self, img_path_list, label_list, transforms=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = data_dir + self.img_path_list[index][1:]\n",
    "        image = cv2.imread(img_path) # 이미지 경로 리스트에서 각 파일 경로 로드\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image']\n",
    "\n",
    "        if self.label_list is not None: # 해당 이미지에 라벨이 있을 경우\n",
    "            label = self.label_list[index] # 이미지에 대한 라벨도 함께 반환\n",
    "            return image, label\n",
    "        else: # 라벨이 없을 경우\n",
    "            return image # 이미지만 반환\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset의 길이가 일정하지 않을 경우 padding을 통해 맞추는 함수 클래스\n",
    "# class CustomCollateFn:\n",
    "#     def __init__(self, transforms=None):\n",
    "#         self.transforms = transforms\n",
    "\n",
    "#     def __call__(self, batch):\n",
    "#         if self.transforms is not None:\n",
    "#             pixel_values = torch.stack([self.transform(data['image']) for data in batch])\n",
    "#             return {\n",
    "#                 'pixel_values':pixel_values,\n",
    "#             }\n",
    "#         else:\n",
    "#             pixel_values = torch.stack([self.transform(data['image']) for data in batch])\n",
    "#             label = torch.LongTensor([data['label'] for data in batch])\n",
    "#             return {\n",
    "#                 'pixel_values':pixel_values,\n",
    "#                 'label':label,\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "                            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "# train dataset 설정 및 로드\n",
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "# val dataset 설정 및 로드\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = model\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Tanh(),\n",
    "            nn.LazyLinear(25),\n",
    "        )\n",
    "\n",
    "#     @torch.compile\n",
    "    def forward(self, x, label=None):\n",
    "        x = self.model(x).pooler_output\n",
    "        x = self.clf(x)\n",
    "        loss = None\n",
    "        if label is not None:\n",
    "            loss = nn.CrossEntropyLoss()(x, label)\n",
    "        probs = nn.LogSoftmax(dim=-1)(x)\n",
    "        return probs, loss\n",
    "\n",
    "class LitCustomModel(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = CustomModel(model)\n",
    "        self.validation_step_output = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.AdamW(self.parameters(), lr=1e-5)\n",
    "        return opt\n",
    "\n",
    "    def training_step(self, batch, batch_idx=None):\n",
    "        x = batch['pixel_values']\n",
    "        label = batch['label']\n",
    "        probs, loss = self.model(x, label)\n",
    "        self.log(f\"train_loss\", loss, on_step=True, on_epoch=False)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx=None):\n",
    "        x = batch['pixel_values']\n",
    "        label = batch['label']\n",
    "        probs, loss = self.model(x, label)\n",
    "        self.validation_step_output.append([probs,label])\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, batch, batch_idx=None):\n",
    "        x = batch['pixel_values']\n",
    "        probs, _ = self.model(x)\n",
    "        return probs\n",
    "\n",
    "    def validation_epoch_end(self, step_output):\n",
    "        pred = torch.cat([x for x, _ in self.validation_step_output]).cpu().detach().numpy().argmax(1)\n",
    "        label = torch.cat([label for _, label in self.validation_step_output]).cpu().detach().numpy()\n",
    "        score = f1_score(label,pred, average='macro')\n",
    "        self.log(\"val_score\", score)\n",
    "        self.validation_step_output.clear()\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=N_SPLIT, random_state=SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "test = pd.read_csv(data_dir + '/test.csv')\n",
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for imgs in tqdm(iter(test_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "\n",
    "            pred = model(imgs)\n",
    "\n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "\n",
    "    preds = le.inverse_transform(preds)\n",
    "    return preds\n",
    "\n",
    "preds = inference(infer_model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
